{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "e0bec266-6977-40ab-b4f0-a7a7adfbbcbd",
      "cell_type": "code",
      "source": "# Welcome to the Lahmas Lab Lascar Data Processor!\n# Please answer the questions below and run your code directly in a jupyter notebook.\n\n# Where is the folder you would like to process?\nfolder_path = r'hydroshare_data' # You can 'copy file path' of the folder in your file manager.\n\n# What are the labels for each variable in the .csv files?\ntime_name = 'Datetime' # Label of time variable\ntemp_name = 'Temperature (�C)' # Label of temperature variable\nrh_name = 'RH (%)' # Label of relative humidity variable\ntd_name = 'Dew Point (�C)' # Label of dew point temperature variable\n\n# What will the name be of your new folder?\nnew_folder_name = 'TestNewFolder' # Don't use spaces or special characters.\n\n# Where would you like this folder to be found after processing?\nnew_folder_path = r'hydroshare_data' # You can 'copy file path' of a folder in your file manager.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "id": "2a5b3330-fe9d-4ae4-ae2c-8e5cf517dca1",
      "cell_type": "code",
      "source": "# Importing all necessary modules\n\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport matplotlib.dates as mdates\nfrom datetime import datetime\nimport io",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "id": "68ab4f8c-c82f-4b74-89f0-eda5277add46",
      "cell_type": "code",
      "source": "# Creating the new folder where all the processed files will end up.\n\nnew_path = new_folder_path + '//'  + new_folder_name\n\nif os.path.exists(new_path):\n    print('\\nThis folder already exists!\\n\\nIf you wish to continue with this folder anyway, \\\nrun the next block.\\nOtherwise, rewrite the folder path/name in block 1.\\n')\n\nelse:\n    os.makedirs(new_path)\n    print('\\nYour new folder path is:\\n\"', new_path, '\"\\n\\nRun next block\\n')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nThis folder already exists!\n\nIf you wish to continue with this folder anyway, run the next block.\nOtherwise, rewrite the folder path/name in block 1.\n\n"
        }
      ],
      "execution_count": 19
    },
    {
      "id": "a30f58d6-6a9c-4474-9c3d-bd6a1363dc5c",
      "cell_type": "code",
      "source": "# File initialization function\n\ndef file_initialize(file_path, time_name, rh_name, td_name):\n\n    ### INITIALIZATION\n    \n    # Prints selected file name\n    print(\"Initializing file:\", os.path.basename(file_path), '\\n')\n\n    # Converting .csv in ANSI encoding to UTF-8 encoding\n    #df = pd.read_csv(file_path, encoding='ANSI')\n    # df.to_csv(file_path, encoding='utf-8', index=False)\n        \n    # Creates dataframe from .csv\n    dataframe = pd.read_csv(file_path)\n    \n    # Skips first values as they may have been taken & tainted during installation\n    dataframe = dataframe.iloc[5:].reset_index(drop=True)\n    \n    # Changes time string to datetime type\n    dataframe['Time_fixed'] = pd.to_datetime(dataframe[time_name])\n    \n    # Define the labels of the corrected variables\n    rh_cor_name = 'RH Corrected (%)'\n    td_cor_name = 'Dew Point Corrected (°C)'\n    \n    \n    ## RH and Td correction\n    \n    # Creating lists to insert corrected RH and Td values\n    RH_cor = [None] * len(dataframe)\n    Td_cor = [None] * len(dataframe)\n    \n    # Iterating through rows to update RH values out of 0-100% range and Td values.\n    for i in range(0,len(dataframe)):\n        if dataframe.loc[i, rh_name] > 100:\n            RH_cor[i] = 100 # RH is adjusted to 100% as it must be saturated\n            Td_cor[i] = dataframe.loc[i, temp_name] # Td is equal to T\n        \n        else: # Everything stays the same\n            RH_cor[i] = dataframe.loc[i, rh_name]\n            Td_cor[i] = dataframe.loc[i, td_name]\n            \n    # Creating columns for the lists to merge into the dataframe\n    dataframe[rh_cor_name] = RH_cor\n    dataframe[td_cor_name] = Td_cor\n    \n    \n    ## Initializing daily and monthly temperature averages for plotting\n    \n    # Create index using the time column\n    dataframe = dataframe.sort_values('Time_fixed')\n    dataframe = dataframe.set_index('Time_fixed', drop=False)\n    \n    # Resample by day and calculate daily min, max, avg for temperature\n    daily_summary_T = dataframe[temp_name].resample('1D')\\\n        .agg(['mean', 'min', 'max']).dropna().reset_index()\n    daily_summary_T.columns = ['Date', 'T_avg', 'T_min', 'T_max']\n    \n    daily_summary_T['DateTime'] = pd.to_datetime(daily_summary_T['Date'])\n    daily_summary_T = daily_summary_T.set_index('Date')\n    monthly_summary_T = daily_summary_T.resample('ME')\\\n        .agg({'T_avg': 'mean','T_min': 'min','T_max': 'max'})\\\n            .dropna().reset_index()\n            \n            \n    ## Initializing daily and monthly relative humidity averages for plotting\n            \n    # Resample by day and calculate daily min, max, avg for RH\n    daily_summary_rh = dataframe[rh_cor_name].resample('1D')\\\n        .agg(['mean', 'min', 'max']).dropna().reset_index()\n    daily_summary_rh.columns = ['DateTime', 'RH_avg', 'RH_min', 'RH_max']\n    \n    # Resample by day and calculate daily min, max, avg for RH\n    daily_summary_rh = dataframe[rh_cor_name].resample('1D')\\\n        .agg(['mean', 'min', 'max']).dropna().reset_index()\n    daily_summary_rh.columns = ['DateTime', 'RH_avg', 'RH_min', 'RH_max']\n    \n    daily_summary_rh['DateTime'] = pd.to_datetime(daily_summary_rh['DateTime'])\n    daily_summary_rh = daily_summary_rh.set_index('DateTime', drop=False)\n    monthly_summary_rh = daily_summary_rh.resample('ME')\\\n        .agg({'RH_avg': 'mean','RH_min': 'min','RH_max': 'max'})\\\n            .dropna().reset_index()\n\n    return dataframe\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "id": "bc818fe2-bf46-41ae-8a19-53c3ab007459",
      "cell_type": "code",
      "source": "# Function writing a new .csv in your new folder\n\ndef write_csv(basename, dataframe):\n\n    # Creating new file path and name\n    new_file_path = new_path + '//PROCESSED_' + os.path.basename(basename)\n    \n    # Prints selected file name\n    print('Writing new file:', os.path.basename(new_file_path), '\\n')\n\n    # Renaming labels to standard\n    dataframe.rename(columns={time_name: 'Datetime (MM/DD/YYYY HR:MN)', \n                              temp_name: 'Temperature (°C)',\n                              rh_name: 'RH (%)',\n                              td_name: 'Dew Point (°C)'}, inplace=True)\n    \n    # Removing custom index\n    dataframe.reset_index(drop=True, inplace=True)\n    \n    # Removing unnecessary columns\n    del dataframe['Time_fixed']\n    \n    # Writing the new dataframe to your computer\n    dataframe.to_csv(new_file_path, index=False, encoding='utf-8-sig')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "id": "4e19ee68-457c-4425-a2b3-334395d04e9b",
      "cell_type": "code",
      "source": "# Walks through the folder and goes through each file one at a time.\n\ndirectory = folder_path\ncounter = 0\ncompleted = []\nskipped = []\n\n# Iterate over files in directory\nfor path, folders, files in os.walk(directory):\n    \n    for filename in files:\n        \n        try:\n            counter = counter + 1\n            print(counter, '.\\n')\n            filename = directory + '//' +filename\n            data = file_initialize(filename, time_name, rh_name, td_name)\n            print('Initialization complete\\n')\n            write_csv(os.path.basename(filename), data)\n            completed.append(os.path.basename(filename))\n\n        except:\n            print('An error occured. File skipped.\\n')\n            skipped.append(os.path.basename(filename))\n\nprint('---------------------------\\n\\nFOLDER TRAVERSED\\n')\nprint('Files processed:\\n', completed, '\\n')\nprint('Files skipped due to error:\\n', skipped)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "1 .\n\nInitializing file: LLanUp-3_17Jul06_9Aug16_4355m.csv \n\nInitialization complete\n\nWriting new file: PROCESSED_LLanUp-3_17Jul06_9Aug16_4355m.csv \n\n2 .\n\nInitializing file: LlanUp-1A_18Jul15_5Jul2019.csv \n\nInitialization complete\n\nWriting new file: PROCESSED_LlanUp-1A_18Jul15_5Jul2019.csv \n\n3 .\n\nInitializing file: LlanUp-1_17Jul06_23Jul15_3955m.csv \n\nInitialization complete\n\nWriting new file: PROCESSED_LlanUp-1_17Jul06_23Jul15_3955m.csv \n\n4 .\n\nInitializing file: LlanUp-2A_18Jul15_5Jul2019.csv \n\nInitialization complete\n\nWriting new file: PROCESSED_LlanUp-2A_18Jul15_5Jul2019.csv \n\n5 .\n\nInitializing file: LlanUp-2_17Jul06_28Jun14_4122m.csv \n\nInitialization complete\n\nWriting new file: PROCESSED_LlanUp-2_17Jul06_28Jun14_4122m.csv \n\n6 .\n\nInitializing file: LlanUp-3A_18Jul15_5Jul2019.csv \n\nInitialization complete\n\nWriting new file: PROCESSED_LlanUp-3A_18Jul15_5Jul2019.csv \n\n7 .\n\nInitializing file: LlanUp-4A_9Jul18_5Jul2019.csv \n\nAn error occured. File skipped.\n\n8 .\n\nInitializing file: LlanUp-4_17Jul06_18Jul15_4561m.csv \n\nAn error occured. File skipped.\n\n9 .\n\nInitializing file: PROCESSED_LLanUp-3_17Jul06_9Aug16_4355m.csv \n\nAn error occured. File skipped.\n\n10 .\n\nInitializing file: PROCESSED_LlanUp-1A_18Jul15_5Jul2019.csv \n\nAn error occured. File skipped.\n\n11 .\n\nInitializing file: PROCESSED_LlanUp-1_17Jul06_23Jul15_3955m.csv \n\nAn error occured. File skipped.\n\n12 .\n\nInitializing file: PROCESSED_LlanUp-2A_18Jul15_5Jul2019.csv \n\nAn error occured. File skipped.\n\n13 .\n\nInitializing file: PROCESSED_LlanUp-2_17Jul06_28Jun14_4122m.csv \n\nAn error occured. File skipped.\n\n14 .\n\nInitializing file: PROCESSED_LlanUp-3A_18Jul15_5Jul2019.csv \n\nAn error occured. File skipped.\n\n---------------------------\n\nFOLDER TRAVERSED\n\nFiles processed:\n ['LLanUp-3_17Jul06_9Aug16_4355m.csv', 'LlanUp-1A_18Jul15_5Jul2019.csv', 'LlanUp-1_17Jul06_23Jul15_3955m.csv', 'LlanUp-2A_18Jul15_5Jul2019.csv', 'LlanUp-2_17Jul06_28Jun14_4122m.csv', 'LlanUp-3A_18Jul15_5Jul2019.csv'] \n\nFiles skipped due to error:\n ['LlanUp-4A_9Jul18_5Jul2019.csv', 'LlanUp-4_17Jul06_18Jul15_4561m.csv', 'PROCESSED_LLanUp-3_17Jul06_9Aug16_4355m.csv', 'PROCESSED_LlanUp-1A_18Jul15_5Jul2019.csv', 'PROCESSED_LlanUp-1_17Jul06_23Jul15_3955m.csv', 'PROCESSED_LlanUp-2A_18Jul15_5Jul2019.csv', 'PROCESSED_LlanUp-2_17Jul06_28Jun14_4122m.csv', 'PROCESSED_LlanUp-3A_18Jul15_5Jul2019.csv']\n"
        }
      ],
      "execution_count": 24
    },
    {
      "id": "6b12af64-001b-4d3e-86c7-a30a794e8247",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7f920312-b536-452d-9196-a32d6492c838",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "fd884b3a-d8fb-4734-8d0e-96120588c7dc",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}