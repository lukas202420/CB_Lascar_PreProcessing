{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "5224e8cb-a275-4db3-b542-2f7211d0edb7",
      "cell_type": "code",
      "source": "# Importing all necessary modules\n\nimport os\nimport pandas as pd\nimport matplotlib.dates as mdates\nfrom datetime import datetime",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0f3e29b5-c1ca-41d3-80f7-2915b40249e2",
      "cell_type": "code",
      "source": "# Welcome to the Lahmas Lab Lascar Data Merger!\n# Please answer the questions below and run your code directly in a jupyter notebook.\n\n# Where are the files you would like to process?\nfiles = {\n    'f1': r'lascar_data/llan lake july 1 2008 lascar HOBO_AWS.txt',\n    'f2': r'lascar_data/HOBO_AWS_7_10_07.txt',\n    'f3': r'lascar_data/HOBO AWS 2-6jul12.txt',\n}\n# ... please continue with [ 'f3': r'', ] etc. if you have more files to add.\n\n# What is the name of the time variable?\ntime_name = 'Time'\n\n# What will the name of the new file be (we recommend replacing .txt with .csv, there should be no issues)?\nnew_file_name = 'HOBO_AWS_17-07-2006_13-07-2009.csv'\n\n# What will your new folder be called?\nnew_folder_name = 'lascar_merged'",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5aabf1dc-5d18-4b4d-b0fc-78d9cafbd55a",
      "cell_type": "code",
      "source": "# Global Variable Editor - DO NOT CHANGE UNLESS YOU ARE SURE\n# This block holds all standardized global variables and formatting styles for the output files.\n\n# Standard Date Format\nstd_date_format = '%Y/%m/%d %H:%M:%S'",
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c6c0eadb-4996-4840-92ff-9e5a35edad11",
      "cell_type": "code",
      "source": "# Creating the new folder where all the processed files will end up.\nnew_folder = '0_' + new_folder_name\n\nif os.path.exists(new_folder):\n    print('\\nThis folder already exists!\\n\\nIf you wish to continue with this folder anyway, \\\nrun the next block.\\nOtherwise, rewrite the folder path/name in block 1.\\n')\n\nelse:\n    os.makedirs(new_folder)\n    print('\\nYour new folder path is:\\n\"', new_folder, '\"\\n\\nRun next block\\n')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d9230b57-dfc3-4d9a-b00b-39e93fd78b68",
      "cell_type": "code",
      "source": "# Merging and sorting both files\n\ndataframe = pd.read_csv(files[f'f1'])\n\nfor i in range(2, len(files) + 1):        \n    data = pd.read_csv(files[f'f{i}'])\n\n    dataframe = pd.concat([dataframe, data])\n\ndataframe['Time_fixed'] = pd.to_datetime(dataframe[time_name], format = 'mixed') # , format = date_format)\n\n# Changing date format to standard\ndataframe['Time_fixed'] = dataframe['Time_fixed'].fillna(std_date_format)\n\n# Updating the time column to standard datetime format\ndataframe[time_name] = dataframe['Time_fixed'].dt.strftime(std_date_format)\n\ndataframe = dataframe.sort_values('Time_fixed').reset_index(drop=True)\n\ndataframe = dataframe.drop_duplicates()\n\ndel dataframe['Time_fixed']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ad76c722-0b4b-4e7c-b725-1ae0feefc8c7",
      "cell_type": "code",
      "source": "# Writing new file into folder\n\nnew_file_path = new_folder + '/' + new_file_name\n\n# Writing the new dataframe to your computer\ndataframe.to_csv(new_file_path, index=False, encoding='utf-8-sig')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}